const generatedBibEntries = {
    "elraoui_2023_agent": {
        "author": "El Raoui, Hanane and Quigley, John and Aslan, Ayse and Vasantha, Gokula and Hanson, Jack and Corney, Jonathan and Sherlock, Andrew",
        "doi": "10.36819/sw23.010",
        "journal": "Proceedings of SW21 The OR Society Simulation Workshop",
        "keywords": "Safety, behaviour, agent based model, accidents, hazardous areas, rewards, safety inspections ,",
        "month": "03",
        "title": "Agent Based Simulation of Workers\u2019 Behaviours Around Hazard Areas in Manufacturing Sites",
        "type": "article",
        "urldate": "2023-05-03",
        "year": "2023"
    },
    "esteso_international": {
        "author": "Esteso, Ana and Peidro, David and Mula, Josefa and D\u00edaz-Madro\u00f1ero, Manuel",
        "doi": "10.1080/00207543.2022.2104180",
        "journal": "",
        "keywords": "Artificial intelligence,machine learning;reinforcement learning, deepreinforcement learning,production planning andcontrol, industry 4.0",
        "title": "International Journal of Production Research Reinforcement learning applied to production planning and control Reinforcement learning applied to production planning and control Artificial intelligence; machine learning; reinforcement learning; deep reinforcement learning; production planning and control; industry 4.0",
        "type": "article",
        "urldate": "2023-05-03"
    },
    "farhan_reinforcement": {
        "author": "Farhan, Mohammed and G\u00f6hre, Brett and Junprung, ",
        "title": "REINFORCEMENT LEARNING IN ANYLOGIC SIMULATION MODELS: A GUIDING EXAMPLE USING PATHMIND",
        "type": "misc",
        "urldate": "2023-05-03"
    },
    "feng_2022_coordinating": {
        "author": "Feng, Siyuan and Duan, Peibo and Ke, Jintao and Yang, Hai",
        "doi": "10.1016/j.trc.2022.103611",
        "journal": "Transportation Research Part C: Emerging Technologies",
        "keywords": "Ride-sourcing service,Multimodal transportation,Reinforcement learning,Order dispatching,Public transit",
        "month": "05",
        "pages": "103611",
        "title": "Coordinating ride-sourcing and public transport services with a reinforcement learning approach",
        "type": "article",
        "urldate": "2023-05-03",
        "volume": "138",
        "year": "2022"
    },
    "huang_2021_event": {
        "author": "Huang, Han Yao and Lee, Tae-Jin and Youn, Hee Yong",
        "doi": "10.1155/2021/6644389",
        "editor": "Anisetti, Marco",
        "journal": "Mobile Information Systems",
        "month": "03",
        "pages": "1-12",
        "title": "Event Driven Duty Cycling with Reinforcement Learning and Monte Carlo Technique for Wireless Network",
        "type": "article",
        "urldate": "2023-05-03",
        "volume": "2021",
        "year": "2021"
    },
    "koch_2020_a": {
        "author": "Koch, Thomas and Dugundji, Elenna",
        "doi": "10.1145/3423335.3428165",
        "journal": "Proceedings of the 3rd ACM SIGSPATIAL International Workshop on GeoSpatial Simulation",
        "month": "11",
        "title": "A review of methods to model route choice behavior of bicyclists",
        "type": "article",
        "urldate": "2023-05-03",
        "year": "2020"
    },
    "lu_2019_incentivebased": {
        "author": "Lu, Renzhi and Hong, Seung Ho",
        "doi": "10.1016/j.apenergy.2018.12.061",
        "journal": "Applied Energy",
        "keywords": "Artificial intelligenceReinforcement learningDeep neural networkIncentive-based demand responseSmart grid",
        "month": "02",
        "pages": "937-949",
        "title": "Incentive-based demand response for smart grid with reinforcement learning and deep neural network",
        "type": "article",
        "urldate": "2023-05-03",
        "volume": "236",
        "year": "2019"
    },
    "ma_2019_hierarchical": {
        "author": "Ma, Aaron and Ouimet, Michael and Cort\u00e9s, Jorge",
        "doi": "10.1007/s10514-019-09871-2",
        "journal": "Autonomous Robots",
        "month": "07",
        "pages": "485-503",
        "title": "Hierarchical reinforcement learning via dynamic subspace search for multi-agent planning",
        "type": "article",
        "urldate": "2023-05-03",
        "volume": "44",
        "year": "2019"
    },
    "polydoros_2017_survey": {
        "author": "Polydoros, Athanasios S. and Nalpantidis, Lazaros",
        "doi": "10.1007/s10846-017-0468-y",
        "journal": "Journal of Intelligent &amp; Robotic Systems",
        "month": "01",
        "pages": "153-173",
        "title": "Survey of Model-Based Reinforcement Learning: Applications on Robotics",
        "type": "article",
        "urldate": "2023-05-03",
        "volume": "86",
        "year": "2017"
    },
    "wang_2020_service": {
        "author": "Wang, Hongman and Li, Yingxue and Zhou, Ao and Guo, Yan and Wang, Shangguang",
        "doi": "10.1002/dac.4413",
        "journal": "International Journal of Communication Systems",
        "month": "04",
        "title": "Service migration in mobile edge computing: A deep reinforcement learning approach",
        "type": "article",
        "urldate": "2023-05-03",
        "volume": "36",
        "year": "2020"
    }
};